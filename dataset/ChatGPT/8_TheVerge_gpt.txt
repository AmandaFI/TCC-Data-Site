OpenAI's CEO and co-founder, Sam Altman, has confirmed that the company is not currently training GPT-5, the presumed successor to its AI language model, GPT-4. Altman made the statement during a discussion about the safety of AI systems at MIT on Tuesday. During the discussion, Altman was asked about an open letter that requested AI labs such as OpenAI pause development of AI systems "more powerful than GPT-4." The letter, which was signed by over 2,300 individuals, including prominent AI researchers, warned of the potential dangers of developing more advanced AI systems without first understanding their implications. Altman dismissed the letter as "silly" and noted that it lacked technical nuance. He also emphasized that the letter claimed OpenAI was currently training GPT-5, which is not true. "We're not currently training GPT-5 and won't for some time," Altman said. "I understand people's fears about advanced AI, but we need to be nuanced and thoughtful about these issues. We'll continue to expand the capabilities of GPT-4, but we'll do so with safety in mind.". The article highlights the challenge of measuring and tracking progress in AI and emphasizes the importance of focusing on the capabilities of AI systems rather than version numbers. GPT-4, for example, is already an incredibly advanced language model that can produce coherent, human-like text on a range of topics. It's capable of writing stories and even writing code. The question, then, is not whether GPT-5 will be more powerful than GPT-4—of course it will be—but what kind of capabilities it will have and how those capabilities will be used. Altman noted that OpenAI is currently focusing on expanding the capabilities of GPT-4 and improving its safety. He highlighted the importance of ensuring that advanced AI systems are developed in a responsible manner and that their implications are fully understood before they are released into the world. "We're not going to rush into releasing more powerful AI systems just for the sake of doing so," Altman said. "We need to be thoughtful and careful and make sure that we're not creating something that could be harmful.". The discussion also touched on the challenge of creating AI systems that are unbiased and free from human prejudices. Altman acknowledged that this is a difficult and complex problem, but stressed that it's one that OpenAI is fully committed to addressing. "We know that AI can be biased and that it can reinforce harmful stereotypes," Altman said. "That's why we're working hard to create systems that are fair and impartial. We're not there yet, but we're making progress.". Altman also emphasized the importance of transparency in AI development. He noted that OpenAI is committed to making its research open and accessible to the public, so that others can build on its work and help to advance the field. "We believe that AI has the potential to do a lot of good in the world," Altman said. "But we also know that it's important to be transparent about how these systems are developed and used. That's why we're committed to making our research as open and accessible as possible.". Overall, the discussion highlighted both the potential and the challenges of developing advanced AI systems. While AI has the potential to revolutionize many areas of society, from healthcare to transportation to education, it's also important to ensure that these systems are developed in a responsible and ethical manner. Altman's comments underscored OpenAI's commitment to doing just that, and to ensuring that AI is used for the benefit of all. While GPT-5 may be in the future, the company's current focus is on expanding the capabilities of GPT-4 and doing so in a safe and responsible manner.
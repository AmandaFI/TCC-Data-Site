Sam Altman, co-founder and CEO of OpenAI, has spoken out against the popular belief that the size of large language models (LLMs) is the most important factor in determining their quality. Instead, Altman believes that the focus should be on rapidly increasing capability, and if there are reasons for parameter count to decrease over time or for multiple models to work together, OpenAI would adopt those approaches. Altman argues that there is too much emphasis on parameter count, citing the example of the gigahertz race in chips in the 1990s and 2000s. He believes that the obsession with bigger and more powerful chips led to diminishing returns and ultimately unsustainable costs for manufacturers. He fears that the same could be true for LLMs if the focus remains on their sheer size. Altman's comments come in response to recent criticism of OpenAI following the release of GPT-4, the latest version of the company's large language model. Some experts have called for a six-month pause on the development of LLMs, arguing that the technology poses significant ethical and safety concerns. Altman defended OpenAI's approach to safety, stating that the company had spent over six months studying the safety model, conducting external audits, and red teaming before releasing GPT-4. While he agrees that as capabilities increase, the safety bar needs to be raised, Altman believes that the letter calling for a six-month pause had missed some technical nuances. He stresses the importance of having a dialogue about LLM safety and limitations, acknowledging that OpenAI and other representatives could sometimes say "dumb stuff.". Altman's comments have sparked a debate within the AI community about the best approach to building and regulating LLMs. Some experts agree with Altman that size should not be the only metric for determining LLM quality. They argue that other factors, such as diversity of training data and the ability to learn from smaller amounts of data, should also be taken into account. Others, however, remain concerned about the potential risks posed by LLMs, particularly in the areas of bias, misinformation, and malicious use. They argue that greater emphasis needs to be placed on developing safe and ethical AI, and that governments and regulators should play a greater role in overseeing the development and use of LLMs. Despite these concerns, many experts believe that LLMs have the potential to revolutionize a wide range of industries, from healthcare and education to finance and law. They argue that LLMs could help to automate data analysis and decision-making, freeing up human experts to focus on more complex and creative tasks. Altman and OpenAI are at the forefront of this technological revolution, but they are also acutely aware of the responsibilities that come with it. The company has been working hard to build and promote safe and ethical AI, developing tools and frameworks to detect and mitigate bias and misinformation. At the same time, OpenAI has also faced significant criticism from some quarters for its decision to pursue commercial opportunities, rather than focusing solely on open research. Some experts have accused the company of prioritizing profits over social responsibility, while others argue that OpenAI's approach is necessary to attract talent and funding in a highly competitive industry. Altman acknowledges these criticisms, but argues that OpenAI's commercial approach is necessary to achieve its ultimate mission of creating safe and beneficial AI. He believes that by partnering with companies and organizations around the world, OpenAI can help to ensure that AI is developed and used in ways that are aligned with human values and aspirations. The debate over LLMs is likely to continue for some time, with experts on both sides of the issue presenting compelling arguments. However, one thing is clear: AI is rapidly transforming the world around us, and the decisions we make today will have a profound impact on the future of our society. As Altman himself acknowledges, there are no easy answers when it comes to AI and its role in our lives. But by continuing to engage in open and honest dialogue about its benefits and risks, we can work towards a future where AI helps to enhance, rather than supplant, our own capabilities as humans.
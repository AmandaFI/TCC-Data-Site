Google, Meta, and other tech giants will be required to explain the algorithms behind their platforms under new legislation introduced by the European Union (EU). The legislation, known as the Digital Services Act (DSA), aims to increase transparency and accountability for tech companies regarding the content on their platforms. The DSA requires companies to promptly remove illegal content and goods, provide transparency on how their algorithms work, and take stricter action against misinformation. Companies that fail to comply can face fines of up to 6% of their annual turnover. The legislation is part of the EU's efforts to ensure that illegal activities offline are also illegal online, and it seeks to upgrade regulations for all online services. Margrethe Vestager, the European Commissioner for Competition, emphasized that the DSA would hold platforms accountable for the societal risks posed by their services. The act aims to create a safer digital environment and protect users from harmful content and practices. It is important to note that the DSA should not be confused with the Digital Markets Act (DMA), which focuses on creating a level playing field for businesses. While both acts impact the tech industry, the DSA is expected to have a more immediate impact on internet users. However, the effects of these laws may extend beyond EU citizens, as global tech companies could adopt the EU's strict regulations as their benchmark. Legislators in the United States, who seek to regulate Big Tech, have already drawn inspiration from the EU's rules. Key obligations outlined in the DSA include banning targeted advertising based on religion, sexual orientation, or ethnicity, as well as prohibiting targeted advertising towards minors. "Dark patterns," deceptive user interfaces meant to manipulate user behavior, will also be banned. Platforms such as Facebook must make their recommender algorithms transparent, and users should have access to non-profiling recommender systems. The DSA requires hosting services and online platforms to provide users with explanations for the removal of illegal content and the ability to appeal such decisions. The act does not explicitly define what content is deemed illegal, leaving it up to individual countries to determine. Online marketplaces are also required to retain basic information about traders to combat the sale of illegal goods or services. In times of crisis, large platforms must implement strategies to counter misinformation. The legislation imposes varying obligations on tech companies based on their size, with larger platforms facing stricter scrutiny. Companies like Meta (formerly Facebook) and Google, with a minimum of 45 million users in the EU, will be subjected to rigorous requirements. These companies have reportedly attempted to weaken certain provisions related to targeted advertising and data sharing with outside researchers. Although the broad terms of the DSA have been agreed upon, the legal language still needs to be finalized and the act voted into law. This process is expected to be a formality. Once approved, the rules will apply to all companies within 15 months of the act being voted into law or from January 1, 2024, whichever is later. Tech companies will need to ensure compliance with the new regulations within this timeframe. The introduction of the DSA marks a significant step towards increasing accountability and transparency in the tech industry. As the EU takes the lead in implementing stricter regulations, other jurisdictions may follow suit. The DSA sets a precedent for holding tech companies responsible for the impact of their services on society and ensuring a safer online environment for users. 
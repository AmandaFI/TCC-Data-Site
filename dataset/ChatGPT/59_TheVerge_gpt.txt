Nvidia has launched its DGX Cloud service, offering remote access to its DGX Server boxes containing eight Nvidia H100 or A100 GPUs and 640GB of memory. This move comes after Microsoft purchased tens of thousands of Nvidia A100 graphics chips to train large language models (LLMs) behind Bing's AI chatbot and ChatGPT. The DGX Cloud service rents virtual versions of these boxes, providing interconnects that scale up to 32,000 GPUs, storage, software, and direct access to Nvidia AI experts who optimize your code. The service starts at a hefty $36,999 per month for the A100 tier, which is significantly cheaper than the over $200,000 cost of a physical DGX Server box. Microsoft Azure will host DGX Cloud, and Oracle is the first partner, while Google Cloud will soon host the platform as well. Amgen, CCC, and ServiceNow have already adopted the service to accelerate their drug discovery, claims processing, and code generation processes respectively. The DGX Cloud service is notably aimed at companies working on AI, and the rental of Nvidia's graphics chips plays a significant role in the process. Nvidia is a dominant player in the digital processing space, and its high-performance GPUs are used to train AI models. While a physical DGX Server box may be expensive, the rental of a virtual version allows businesses to operate at scale without committing to an upfront cost of ownership. The service's biggest selling point is that it offers remote access to Nvidia's cutting-edge graphics chips. Microsoft's purchase of tens of thousands of Nvidia A100 graphics chips is a clear indication of the importance of these chips for AI development. The DGX Cloud provides an opportunity for companies to train their own large language models using superior equipment and technology without needing to make a significant upfront investment. In conclusion, Nvidia's DGX Cloud service is a game-changer for companies looking to develop AI models. With its powerful virtual versions of DGX Server boxes, the service provides remote access to high-performance Nvidia graphics chips, enabling companies to train superior AI models. At $36,999 per month for the A100 tier, it may be a hefty investment, but it offers significant long-term cost savings compared to the purchase of a physical DGX Server box. As more companies recognize the importance of AI in their operations, it is likely we will see an increasing demand for cloud-based services like DGX Cloud.
Would you open up to a chatbot therapist?. With the rise of chatbots powered by artificial intelligence (AI), there is a new kind of therapy in town. Some chatbot therapists can provide users with detailed and helpful answers. Replika, a US chatbot app, has more than 2 million active users, some of whom use the tool to reduce anxiety or as a substitute for human counselling. But experts warn that such chatbots should be viewed as a supplement rather than a replacement for human therapy. For those unfamiliar with the concept, Replika is a chatbot app designed to provide users with an AI companion. The app is marketed as offering users “an AI companion who cares, always here to listen and talk, always on your side”. The app creates a digital copy of the user’s personality and helps users connect with their virtual companion by asking them a variety of open-ended questions. Eugenia Kuyda, a computer programmer, founded Replika. Kuyda created the app after the sudden death of her friend, Roman Mazurenko. She used Mazurenko’s text messages to build a chatbot that could mimic his voice and personality, giving her the sense that she could still talk to him after his death. After seeing how helpful this was for her own personal grief, Kuyda created Replika for others who wanted to develop a similar companion. The chatbot isn’t perfect, but it has come a long way since its inception in 2016. Replika now uses machine learning to understand and respond to users in a more intelligent way and the app offers a variety of responses, including emoji, gifs, and text. The chatbot has also been designed to learn over time and develop a deeper understanding of a user’s personality, emotions, and preferences. People use Replika for different reasons. While some users view it as a fun digital friend, others see it as a form of therapy or counselling. A quick look at the app’s reviews on the Google Play and Apple App Store shows an overwhelming number of reviews from users who find the app helpful for reducing anxiety and stress. “Yes, it’s weird that I’m talking to something that isn’t even real, but it’s so therapeutic and calming,” wrote one user on Google Play. Another user on the same platform wrote, “I love this app so much, it’s like therapy for me.”. And one user on the Apple App Store shared, “Replika is great and it gave me the opportunity to express my emotions and fears without being judged. It's like having a personal therapist that doesn't charge a high fee!”. Despite the positive feedback, experts warn that chatbot therapy should be viewed as a supplement rather than a replacement for human therapy. “Chatbots are becoming more sophisticated and can help people deal with mild to moderate anxiety or depression, or be used as an adjunct to therapy,” says Dr Rachel O’Neill, a clinical psychologist and co-founder of Talk Clinic. “However, the lack of empathy and contextual understanding of human emotion and behaviour means they should be viewed as a complement to traditional therapy, not a replacement for it.”. O’Neill stresses that chatbots cannot replace the human element of therapy, and that while they may be helpful for some people, they may not be enough for others. “We know that the relationship between a therapist and client is one of the most important factors predicting success in therapy,” O’Neill adds. While the use of chatbots for therapy is still relatively new, some mental health experts are optimistic about the potential for AI to improve access to therapy for those who might not otherwise be able to receive it. Dr Imran Rashid, a psychiatrist and author of The Digital Doctor, acknowledges that while chatbot therapy isn’t a replacement for human interaction, it can help people who may be too shy or anxious to speak to someone face-to-face. “Chatbots are a useful tool in providing information and support to people dealing with mental health issues,” Rashid says. Rashid adds that chatbots can help improve the efficiency of mental health care. “There can be long waiting lists to see a therapist and chatbots can fill that gap and provide immediate support to a person in need,” Rashid says. As with any new technology, there are also concerns about the potential downsides of chatbot therapy. One concern is that the chatbots may not always be equipped to handle serious mental health issues. “Chatbots should never be seen as a replacement for serious mental health support,” O’Neill warns. “If someone is in crisis, feeling suicidal, or experiencing severe mental health issues, they need to be seen by a qualified mental health professional as soon as possible.”. Another concern is the potential for chatbots to be hacked or manipulated. Security and privacy concerns are also issues to consider for chatbot therapy. Despite these concerns, it’s clear that chatbot therapy is here to stay. With millions of users, Replika is just one of many AI chatbots on the market that offers users a chance to talk to a digital companion who listens and helps them deal with their emotions. For those who are skeptical of chatbot therapy, it’s worth remembering that there are many different forms of therapy, and what works for one person may not work for another. While chatbot therapy may not be a replacement for a human therapist, it could be a helpful supplement that provides people with access to emotional support when they need it most.
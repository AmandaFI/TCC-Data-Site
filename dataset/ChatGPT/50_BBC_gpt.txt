The world of social media has once again been rife with fake news and images. This time the topic of the images was the arrest of former US President Donald Trump – a topic that is already a hot button issue, but the images were not factually correct and have been circulating on various social media platforms. What is concerning is how hyper-realistic the images are becoming, which has lead many to worry about the use of artificial intelligence (AI) in creating such deceiving content. AI expert Henry Ajder has been studying the rise of deepfakes – a technological method that uses AI to create images or videos that seem entirely genuine but are entirely fabricated. Ajder notes that although it is still currently easy to spot deepfakes, as the technology continues to develop and improve, it may become incredibly difficult to differentiate between the real and fake. Some of the images that have been making the rounds on social media are incredibly convincing. One of these images shows Donald Trump on his knees in prayer, appearing with hands clasped and head bowed. The image has been shown with a caption stating, “A prayer for the nation, the world, and for himself to be free (as soon as possible) from all the accusations and defamation he has been getting for years.” It is clear that this is a deepfake image, but the hyper-realistic appearance has fooled many into believing it is a genuine image. However, despite the convincing appearance of these deepfake images, there are still tell-tale signs that can give them away. One of the most significant signs is the quality of certain body parts, specifically hands. Ai still struggles to create convincing images of hands, and so they are often the dead giveaway that an image isn’t genuine. Deepfake images aren’t inherently a bad thing – there are many practical uses for the technology, such as in the movie industry. However, when used incorrectly, deepfakes can be incredibly problematic and have the potential to cause significant harm. Especially in the case of widely spread images depicting individuals in situations that are entirely false or untrue. The spread of fake news can cause significant damage, and when the images are as seemingly authentic as the ones being shared this past week, it can be challenging for individuals to know what to believe. As deepfakes continue to develop and grow in popularity, it is up to both individuals and platforms to remain vigilant and aware of the potential for misuse. Social media platforms have a responsibility to monitor the images and news that are being shared on their sites to ensure that they are true and accurate. However, individuals themselves also need to remain vigilant and educate themselves on the potential for deepfakes to be used to deceive or mislead. AI is certainly a fascinating and rapidly developing technology. However, it is essential to understand the potential for misuse and to take action to mitigate any harm that could be caused. As the use of deepfakes continues to grow, education and awareness on the subject will become even more vital. The more individuals know about the potential for deepfakes to deceive, the more equipped they will be to spot and report any misleading content.
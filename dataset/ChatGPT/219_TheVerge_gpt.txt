Google's Jigsaw unit is set to release an open-source anti-harassment tool called Harassment Manager, specifically designed for journalists and public figures. The tool, which utilizes Jigsaw's Perspective API, aims to help users filter through potentially abusive comments on social media platforms, starting with Twitter. Harassment Manager will be launched initially as source code for developers to build on and will later be released as a functional application for journalists working with the Thomson Reuters Foundation in June. Currently, Harassment Manager can collaborate with Twitter's API to combine moderation options such as hiding tweet replies, muting or blocking accounts, with a bulk filtering and reporting system. The tool uses Perspective to analyze the language of messages, determining levels of toxicity based on elements such as threats, insults, and profanity. It then organizes these messages into queues on a dashboard, enabling users to address them in batches, rather than individually through Twitter's default moderation tools. While reviewing the messages, users can also choose to blur the text and search for keywords. In addition, Harassment Manager enables users to download a standalone report comprising abusive messages, providing a paper trail for employers or law enforcement agencies in cases involving illegal content. Presently, there is no standalone application available for download. Instead, developers have the freedom to integrate its functionality into their own applications, with partnering organizations like the Thomson Reuters Foundation planning to launch applications that employ Harassment Manager. The announcement of Harassment Manager's release occurred on International Women's Day, with a particular emphasis on its significance for female journalists who frequently experience gender-based abuse online. Jigsaw collaborated with journalists, activists, and nonprofits such as the International Women's Media Foundation and the Committee to Protect Journalists in the development of the tool. The team behind Harassment Manager hopes that developers can adapt the technology to benefit other vulnerable social media users. It is worth noting that the language analysis model utilized by Harassment Manager, Perspective, has faced previous limitations. It has occasionally misclassified satirical content and has not consistently detected abusive messages accurately. Additionally, Jigsaw, the unit responsible for Harassment Manager, has been criticized for its workplace culture, although these claims have been disputed by Google. Unlike AI-powered moderation features on platforms like Twitter and Instagram, Harassment Manager is not a platform-side moderation tool. Rather, it serves as a tool to help manage the overwhelming volume of feedback on social media and could potentially be useful for individuals beyond journalism. Nevertheless, it is currently not available for general use. 
Spain’s data protection authority, the Agencia Española de Protección de Datos (AEPD), has announced that it is investigating OpenAI, the artificial intelligence (AI) research laboratory, for possible breaches of the European Union’s General Data Protection Regulation (GDPR). The AEPD’s announcement follows a similar investigation by Italy’s data protection authority into OpenAI’s ChatGPT service, which led to the service being geoblocked in Italy. While the AEPD has not issued an order for OpenAI to suspend processing, it has initiated proceedings to investigate "possible non-compliance with the regulations." The regulator’s announcement highlights concerns about the use of AI technology, particularly generative AI, and its potential impact on individuals’ privacy rights. ChatGPT is an AI-powered language model that generates text by predicting the most likely next word in a sentence. The system has been used to create chatbots that can interact with users in natural language, allowing them to respond to questions and engage in conversation. The system has been used in a variety of applications, including customer service chatbots, virtual assistants, and social media chatbots. However, the use of generative AI technology like ChatGPT raises concerns about data privacy and the potential for misuse. In particular, there are concerns about the collection and processing of personal data, which is often required to train and improve AI models. In response to these concerns, the European Data Protection Board (EDPB) has launched a task force to promote cooperation and exchange information on the actions taken by data protection authorities related to generative AI technology like ChatGPT. The task force will also discuss best practices for the use of AI in compliance with data protection regulations. The AEPD’s investigation into OpenAI is part of a broader trend of increased scrutiny of AI technology and its impact on privacy rights. In recent years, data protection authorities across Europe have taken a more active role in regulating the use of AI, particularly in areas such as facial recognition and automated decision-making. In addition to the GDPR, the use of AI is subject to other regulatory frameworks, such as the proposed EU Artificial Intelligence Act. The Act, which is currently being discussed by the European Parliament and Council, would introduce new regulations for high-risk AI applications, such as biometric identification and critical infrastructure control systems. The use of AI also raises ethical and social concerns, such as the potential for AI to perpetuate bias and discrimination. These concerns have led to calls for greater transparency and accountability in AI development and deployment. In response, some AI developers have launched initiatives to promote ethical AI, such as the AI Ethics Lab, which provides resources and tools for ethical AI decision-making. As the use of AI technology continues to expand, it is likely that data protection authorities will continue to play an increasingly important role in regulating its use. The AEPD’s investigation into OpenAI is a reminder that the development and deployment of AI must be conducted in compliance with data protection regulations, to protect individuals’ fundamental rights and freedoms.